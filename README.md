# üèõÔ∏è Jus-Scraper: Extra√ß√£o Automatizada de Publica√ß√µes Judiciais do DJE-TJSP

Este projeto √© uma aplica√ß√£o de web scraping desenvolvida em Python para extrair publica√ß√µes do Di√°rio da Justi√ßa Eletr√¥nico (DJE) do Tribunal de Justi√ßa de S√£o Paulo (TJSP). Ele √© capaz de baixar PDFs, extrair dados estruturados dessas publica√ß√µes (como n√∫mero de processo, autores, advogados e valores) e, opcionalmente, enviar esses dados para uma API externa. Al√©m disso, ele oferece funcionalidades para organizar e gerenciar os downloads.

## ‚ú® Funcionalidades

* **Extra√ß√£o do Site:** Realiza buscas no DJE-TJSP por publica√ß√µes de uma data espec√≠fica, baixando os PDFs relevantes.
* **Processamento de PDFs:** Extrai automaticamente informa√ß√µes estruturadas (n√∫mero de processo, autores, advogados, valores de principal, juros e honor√°rios, e conte√∫do completo) de PDFs locais.
* **Deduplica√ß√£o Inteligente:** Remove publica√ß√µes duplicadas com base no n√∫mero do processo antes do envio e do salvamento local, movendo PDFs duplicados para uma pasta espec√≠fica.
* **Integra√ß√£o com API:** Envia as publica√ß√µes extra√≠das e deduplicadas para uma API externa (configur√°vel).
* **Gerenciamento de Downloads:** Ferramentas para listar, renomear, organizar por data e limpar arquivos PDF baixados.
* **Automa√ß√£o com Docker e Cron:** Configura√ß√£o para rodar a extra√ß√£o e o envio √† API automaticamente em um hor√°rio programado dentro de um container Docker.

## ‚öôÔ∏è Pr√©-requisitos

Para rodar este projeto, voc√™ precisar√° de:

* **Python 3.9+**
* **pip** (gerenciador de pacotes Python)
* **Google Chrome** instalado no seu sistema (para execu√ß√£o local, o `chromedriver` ser√° gerenciado pelo Selenium).
* **Docker Desktop** (para execu√ß√£o containerizada).
* Um **endpoint de API** para o envio dos dados (ex: `http://localhost:3000/api/publicacoes`).

## üöÄ Instala√ß√£o

1.  **Clone o reposit√≥rio:**
    ```bash
    git clone [https://github.com/seu-usuario/jus-scraper.git](https://github.com/seu-usuario/jus-scraper.git)
    cd jus-scraper
    ```
2.  **Instale as depend√™ncias Python:**
    ```bash
    pip install -r requirements.txt
    ```

## üèÉ Como Rodar

Existem duas formas principais de executar a aplica√ß√£o: **localmente (interativo)** e **containerizada (automatizada via Docker)**.

### A. Execu√ß√£o Local (Interativa)

Voc√™ pode rodar o scraper e suas ferramentas diretamente do seu ambiente Python.

1.  **Navegue at√© o diret√≥rio `src/scraper`:**
    ```bash
    cd src/scraper
    ```
2.  **Execute o scraper principal:**
    ```bash
    python dje_scraper.py
    ```
    Um menu de op√ß√µes ser√° exibido:
    ```
    OP√á√ïES:
    1. Extrair do site (com download)
    2. Processar PDFs j√° baixados
    3. Listar downloads
    4. Limpar downloads antigos
    5. Enviar publica√ß√µes para a API (ap√≥s extra√ß√£o ou processamento de PDFs)
    ```
    * **Op√ß√µes 1 ou 2:** Realizam a extra√ß√£o e o processamento dos dados. Ao final, o script perguntar√° se voc√™ deseja enviar os resultados para a API.
    * **Op√ß√£o 5:** Processa os PDFs existentes na pasta de downloads (`./downloads_dje`) e, em seguida, tenta enviar os resultados deduplicados para a API.

3.  **Execute o organizador de downloads (opcional):**
    Para gerenciar os PDFs baixados, voc√™ pode usar o `organizador_downloads.py`.
    ```bash
    python organizador_downloads.py
    ```
    Este script tamb√©m apresentar√° um menu interativo para an√°lise, renomea√ß√£o, remo√ß√£o de duplicatas e organiza√ß√£o por data.

### B. Execu√ß√£o Dockerizada (Automatizada)

Para uma execu√ß√£o cont√≠nua e automatizada (ex: em um servidor), recomenda-se usar Docker. A imagem Docker configurar√° um trabalho `cron` para executar a extra√ß√£o e o envio √† API diariamente √† 1h da manh√£ (hor√°rio do container, configurado para `America/Sao_Paulo`).

1.  **Navegue at√© o diret√≥rio raiz do projeto (`jus-scraper/`):**
    ```bash
    cd jus-scraper
    ```
2.  **Construa a imagem Docker:**
    ```bash
    docker build -t jus-scraper-automated .
    ```
3.  **Execute o container Docker:**
    √â crucial que a sua API esteja acess√≠vel pelo container Docker. Se a API estiver rodando na mesma m√°quina, voc√™ pode usar `host.docker.internal` (para Docker Desktop) ou o IP da m√°quina host (para VPS) na vari√°vel `API_BASE_URL`.

    ```bash
    docker run -d --name jus-scraper-runner \
    -e API_BASE_URL="[http://host.docker.internal:3000](http://host.docker.internal:3000)" \
    -e API_KEY="sua_chave_api_se_tiver" \
    -e API_SECRET="seu_secret_api_se_tiver" \
    jus-scraper-automated
    ```
    * `-d`: Roda o container em modo "detached" (em segundo plano).
    * `--name jus-scraper-runner`: Atribui um nome amig√°vel ao seu container.
    * `-e API_BASE_URL="..."`: Define a URL da sua API. **Ajuste este valor!**
    * `-e API_KEY="..."`, `-e API_SECRET="..."`: Se sua API requer autentica√ß√£o, defina estas vari√°veis.
    * `jus-scraper-automated`: O nome da imagem Docker que voc√™ construiu.

4.  **Verificar Logs:**
    Para acompanhar a execu√ß√£o do `cron` e do script Python dentro do container:
    ```bash
    docker logs -f jus-scraper-runner
    ```
    Os logs detalhados das execu√ß√µes di√°rias ser√£o armazenados dentro do container em `/var/log/cron/daily_scrape.log` e `/app/src/logs/daily_run.log`. Voc√™ pode acess√°-los com `docker exec`:
    ```bash
    docker exec jus-scraper-runner cat /var/log/cron/daily_scrape.log
    docker exec jus-scraper-runner cat /app/src/logs/daily_run.log
    ```

## üîó Integra√ß√£o com API

A aplica√ß√£o envia as `Publicacao`es extra√≠das e deduplicadas para o endpoint `/api/publicacoes` da sua API. O modelo `Publicacao` (`src/models/publicacao.py`) define a estrutura dos dados enviados. A deduplica√ß√£o √© realizada localmente antes do envio, garantindo que apenas registros √∫nicos sejam submetidos.

As configura√ß√µes da API, incluindo a URL base, timeout e cabe√ßalhos de autentica√ß√£o, s√£o gerenciadas em `src/api/config.py` e podem ser sobrescritas por vari√°veis de ambiente (`API_BASE_URL`, `API_KEY`, `API_SECRET`).

## ‚öôÔ∏è Configura√ß√£o

Voc√™ pode ajustar algumas configura√ß√µes por meio de vari√°veis de ambiente ou editando os arquivos de configura√ß√£o:

* **`API_BASE_URL`**: A URL base da sua API (padr√£o: `http://localhost:3000`). Pode ser configurada via vari√°vel de ambiente ou em `src/api/config.py`.
* **`API_KEY`**, **`API_SECRET`**: Chaves de autentica√ß√£o para sua API, se necess√°rio. Configuradas via vari√°veis de ambiente ou em `src/api/config.py`.
* **Par√¢metros de Busca:** A data de busca e os termos de pesquisa (`"RPV" e "pagamento pelo INSS"`) est√£o definidos no `src/scraper/dje_scraper.py` e podem ser ajustados.

## üìù Logging

A aplica√ß√£o utiliza o m√≥dulo `src/utils/logger.py` para registrar as opera√ß√µes.
Os logs s√£o salvos em:
* `./logs/dje_scraper_AAAA_MM_DD.log` (para execu√ß√µes locais interativas)
* `/var/log/cron/daily_scrape.log` (logs do cron no Docker)
* `/app/src/logs/daily_run.log` (logs do script de execu√ß√£o di√°ria no Docker)

##  troubleshooting

* **`FileNotFoundError` ou `No such file or directory`:** Verifique se as pastas `data/cache`, `data/results`, `data/backups`, `data/downloads_dje`, e `logs` existem na raiz do projeto. O script as cria, mas permiss√µes ou erros de caminho podem causar problemas.
* **Selenium/Chrome Erros:**
    * **Local:** Certifique-se de que o Google Chrome est√° instalado e atualizado.
    * **Docker:** O `Dockerfile` j√° instala `chromium-browser` e `chromium-chromedriver`. Verifique os logs do Docker para mensagens de erro relacionadas ao navegador. Certifique-se de que a flag `--headless` est√° configurada para ambientes sem GUI.
* **Conex√£o com a API:**
    * Verifique se sua API est√° rodando e acess√≠vel no endere√ßo configurado (`API_BASE_URL`).
    * Se estiver usando Docker, confirme se o `API_BASE_URL` est√° configurado corretamente para o ambiente do container (ex: `host.docker.internal` ou o IP da m√°quina host).
* **Permiss√µes:** Em ambientes Linux/Docker, certifique-se de que os arquivos e diret√≥rios t√™m as permiss√µes corretas para leitura e escrita pelo usu√°rio que executa a aplica√ß√£o.
